{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QPgoEjvMaCt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "\n",
        "mlp_model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "mlp_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nTraining MLP model...\")\n",
        "mlp_history = mlp_model.fit(x_train, y_train,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            epochs=10, batch_size=128, verbose=1)\n",
        "\n",
        "\n",
        "cnn_model = models.Sequential([\n",
        "    data_augmentation,\n",
        "\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nTraining CNN model...\")\n",
        "cnn_history = cnn_model.fit(x_train, y_train,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            epochs=10, batch_size=128, verbose=1)\n",
        "\n",
        "\n",
        "def plot_metric(histories, metric, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for name, history in histories.items():\n",
        "        plt.plot(history.history[metric], label=f'{name} Train')\n",
        "        plt.plot(history.history[f'val_{metric}'], '--', label=f'{name} Val')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_metric({'MLP': mlp_history, 'CNN': cnn_history},\n",
        "             'accuracy', 'Training and Validation Accuracy Comparison')\n",
        "plot_metric({'MLP': mlp_history, 'CNN': cnn_history},\n",
        "             'loss', 'Training and Validation Loss Comparison')\n",
        "\n",
        "\n",
        "mlp_acc = mlp_model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "cnn_acc = cnn_model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "\n",
        "print(f\"\\nFinal Test Accuracy:\")\n",
        "print(f\"MLP: {mlp_acc:.4f}\")\n",
        "print(f\"CNN: {cnn_acc:.4f}\")"
      ]
    }
  ]
}
