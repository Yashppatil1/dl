{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7iYokzYNp0Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)\n",
        "\n",
        "\n",
        "baseline_model = models.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "baseline_model.compile(optimizer='adam',\n",
        "                       loss='sparse_categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "baseline_history = baseline_model.fit(x_train, y_train,\n",
        "                                      validation_data=(x_test, y_test),\n",
        "                                      epochs=10, batch_size=128, verbose=0)\n",
        "\n",
        "l2_model = models.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=(784,),\n",
        "                 kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dense(128, activation='relu',\n",
        "                 kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "l2_model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "l2_history = l2_model.fit(x_train, y_train,\n",
        "                          validation_data=(x_test, y_test),\n",
        "                          epochs=10, batch_size=128, verbose=0)\n",
        "\n",
        "\n",
        "dropout_model = models.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=(784,)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "dropout_model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "dropout_history = dropout_model.fit(x_train, y_train,\n",
        "                                    validation_data=(x_test, y_test),\n",
        "                                    epochs=10, batch_size=128, verbose=0)\n",
        "\n",
        "\n",
        "def plot_metrics(histories, metric='accuracy'):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    for name, history in histories.items():\n",
        "        plt.plot(history.history[metric], label=f'{name} Train')\n",
        "        plt.plot(history.history[f'val_{metric}'], '--', label=f'{name} Val')\n",
        "    plt.title(f'Model {metric.capitalize()} Comparison')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_metrics({\n",
        "    'Baseline': baseline_history,\n",
        "    'L2 Regularization': l2_history,\n",
        "    'Dropout': dropout_history\n",
        "}, 'accuracy')\n",
        "\n",
        "\n",
        "plot_metrics({\n",
        "    'Baseline': baseline_history,\n",
        "    'L2 Regularization': l2_history,\n",
        "    'Dropout': dropout_history\n",
        "}, 'loss')\n",
        "\n",
        "\n",
        "print(\"Final Test Accuracy:\")\n",
        "print(f\"Baseline: {baseline_model.evaluate(x_test, y_test, verbose=0)[1]:.4f}\")\n",
        "print(f\"L2 Regularization: {l2_model.evaluate(x_test, y_test, verbose=0)[1]:.4f}\")\n",
        "print(f\"Dropout: {dropout_model.evaluate(x_test, y_test, verbose=0)[1]:.4f}\")"
      ]
    }
  ]
}
