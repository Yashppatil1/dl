{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTUG1lJfJKOH",
        "outputId": "ab5b8e06-7285-446b-d60f-e6fb7732e77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "LR=0.001, Batch=32, DenseLayers=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9817\n",
            "\n",
            "LR=0.001, Batch=32, DenseLayers=2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1,28,28,1)/255.0\n",
        "X_test  = X_test.reshape(-1,28,28,1)/255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test  = to_categorical(y_test)\n",
        "\n",
        "\n",
        "def build_model(lr, dense_layers):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "    ])\n",
        "\n",
        "\n",
        "    for _ in range(dense_layers):\n",
        "        model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "learning_rates = [0.001, 0.01]\n",
        "batch_sizes = [32, 64]\n",
        "layers_option = [1, 2]\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        for L in layers_option:\n",
        "            log_dir = f\"logs/lr{lr}_bs{bs}_L{L}\"\n",
        "            tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "            print(f\"\\nLR={lr}, Batch={bs}, DenseLayers={L}\")\n",
        "            model = build_model(lr, L)\n",
        "            model.fit(X_train, y_train, epochs=2, batch_size=bs,\n",
        "                      validation_split=0.1, callbacks=[tb], verbose=0)\n",
        "\n",
        "            loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "            print(f\"Accuracy: {acc:.4f}\")"
      ]
    }
  ]
}